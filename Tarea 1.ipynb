{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856b9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb89273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334a39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets_2022_abril_junio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f0be6",
   "metadata": {},
   "source": [
    "#### Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e92a2",
   "metadata": {},
   "source": [
    "Se filtran Tweets con el mismo id, quedando en el dataframe la primera aparici√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39df083",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop_duplicates(subset=['id'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779d4c2",
   "metadata": {},
   "source": [
    "Se filtran las columnas que no son de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22cf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop(columns=['created_at', 'favorite_count', 'retweet_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a634f05",
   "metadata": {},
   "source": [
    "#### Procesamiento de Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ffd84",
   "metadata": {},
   "source": [
    "Se preprocesan los tweets, con el objetivo de estandarizar palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c825c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de stop words en espa√±ol\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    # Quitar las tildes y convertir las letras a min√∫sculas\n",
    "    tweet = unidecode(tweet).lower()\n",
    "    \n",
    "    # Eliminar enlaces\n",
    "    tweet = re.sub(r'(http\\S+)', '', tweet)\n",
    "    \n",
    "    # Eliminar todos los caracteres que no sean alfanum√©ricos o espacios\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    \n",
    "    # Tokenizar el tweet y eliminar stop words y palabras de menos de 3 caracteres\n",
    "    tweet = ' '.join([token for token in tweet.split() if token not in stop_words and len(token) > 2])\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "893107a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4592806/4592806 [01:26<00:00, 53310.55it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_tweets = tweets.copy()\n",
    "\n",
    "# Aplicar la funci√≥n de preprocesamiento\n",
    "processed_tweets['text'] = processed_tweets['text'].progress_apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f966c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usuario encanta naturaleza visita sol brillante cielo azul airelibre'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_example = \"@usuario Me encanta la #Naturaleza! Visita https://miweb.com. El sol es brillante y el cielo azul. #AireLibre\"\n",
    "\n",
    "preprocess_tweet(tweet_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9181ce7e",
   "metadata": {},
   "source": [
    "#### Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "925dd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_shingles(texts, k=3):\n",
    "    all_shingles = {}\n",
    "    unique_id = 1\n",
    "\n",
    "    # Generar los shingles\n",
    "    for text in tqdm(texts, desc='Calculando shingles', unit='texto'):\n",
    "        for i in range(len(text) - k + 1):\n",
    "            shingle = text[i:i + k]\n",
    "            if shingle not in all_shingles:\n",
    "                all_shingles[shingle] = unique_id\n",
    "                unique_id += 1\n",
    "\n",
    "    return all_shingles\n",
    "\n",
    "def get_k_shingles(s, k=3):\n",
    "    \"\"\"Genera los k-shingles de una cadena de texto\"\"\"\n",
    "    return set([s[i:i+k] for i in range(len(s) - k + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf713b49",
   "metadata": {},
   "source": [
    "#### Similitud de Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53f4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Computa la similitud de Jaccard entre dos sets\"\"\"\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union) if len(union) != 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912226c",
   "metadata": {},
   "source": [
    "## Proceso de exploraci√≥n para obtener k y s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40bd48",
   "metadata": {},
   "source": [
    "Tomamos una muestra de 1.000 datos, para ver cuales son los valores de k y s mas optimos, considerando resultado de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438f2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample = processed_tweets.sample(n=1_000, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc5f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Funci√≥n para encontrar los pares de tweets en percentiles espec√≠ficos\n",
    "def find_tweet_pairs(df, k, s):\n",
    "    \n",
    "    # Calcular los shingles para cada tweet en el DataFrame\n",
    "    df['shingles'] = df['text'].apply(lambda x: get_k_shingles(x, k))\n",
    "\n",
    "    # Calcular la similitud de Jaccard entre todos los pares de tweets en el DataFrame\n",
    "    pairs = list(combinations(df.index, 2))\n",
    "    total_pairs = len(pairs)\n",
    "    similarities = []\n",
    "    with tqdm(total=total_pairs, desc='Calculando similitud', unit='par') as pbar:\n",
    "        for pair in pairs:\n",
    "            tweet1 = df.loc[pair[0]]\n",
    "            tweet2 = df.loc[pair[1]]\n",
    "            \n",
    "            # Verificar si los nombres de usuario son diferentes\n",
    "            if tweet1['screen_name'] != tweet2['screen_name']:\n",
    "                similarity = jaccard_similarity(tweet1['shingles'], tweet2['shingles'])\n",
    "                \n",
    "                # Filtrar los pares de tweets basados en la similitud de Jaccard\n",
    "                if similarity >= s:\n",
    "                    similarities.append((pair[0], pair[1], similarity))\n",
    "                \n",
    "            pbar.update(1)\n",
    "\n",
    "    # Ordenar los pares de tweets por similitud\n",
    "    similarities.sort(key=lambda x: x[2])\n",
    "\n",
    "    # Obtener los tweets correspondientes a los pares en los percentiles espec√≠ficos\n",
    "    percentiles = [0, 25, 50, 75, 95]\n",
    "    results = {}\n",
    "    for percentile in percentiles:\n",
    "        index = int(len(similarities) * percentile / 100)\n",
    "        pair = similarities[index]\n",
    "        tweet1 = df.loc[pair[0]]\n",
    "        tweet2 = df.loc[pair[1]]\n",
    "        results[percentile] = (tweet1['text'], tweet2['text'])\n",
    "\n",
    "    # Imprimir los resultados\n",
    "    for percentile, pair in results.items():\n",
    "        print(f\"Percentil {percentile}:\")\n",
    "        print(f\"Tweet 1: {pair[0]}\")\n",
    "        print(f\"Tweet 2: {pair[1]}\")\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "    # Imprimir la cantidad de pares similares y el porcentaje respecto al total de pares\n",
    "    num_similar_pairs = len(similarities)\n",
    "    similarity_percentage = num_similar_pairs / total_pairs * 100\n",
    "    print(f\"Cantidad de pares similares (s >= {s}): {num_similar_pairs} ({similarity_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41630ab6",
   "metadata": {},
   "source": [
    "#### k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25d1ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando similitud: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 499500/499500 [00:24<00:00, 20642.97par/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentil 0:\n",
      "Tweet 1: angeldlacruz_ alerta confirma convencion actual gobierno boric izquierda quieren expropiar robar ahorros\n",
      "Tweet 2: danielverdessi despues escuchar convencional marcos barraza cooperativa queda claro propuesta politica impuls\n",
      "------------------------------\n",
      "Percentil 25:\n",
      "Tweet 1: mister_wolf_0 rocio fake cantuarias cerrar debate convencional despacha serie mentiras derechos\n",
      "Tweet 2: bsepulvedahales derecha quiere apoyar domingos dias habiles trabajo constituyente argumentos\n",
      "------------------------------\n",
      "Percentil 50:\n",
      "Tweet 1: stelartoqui pepe_auth ignacioachurra mineria dano naturaleza banco central autonomo intereses elitistas derecho propi\n",
      "Tweet 2: nachomaturana gracias valiente incansablemente peleando chile tere_marinovic rocicantuarias arancibial\n",
      "------------------------------\n",
      "Percentil 75:\n",
      "Tweet 1: retirototalafp tere_marinovic explica paso paso expropiaran ahorros quintoretirourgente retirototalafp qui\n",
      "Tweet 2: tere_marinovic gravisimo constituyentes acaban anunciar nueva trampa ahora incluir normas transitorias forma\n",
      "------------------------------\n",
      "Percentil 95:\n",
      "Tweet 1: pcsandov t13 berfontaine tere_marinovic obvio haber expropiacion fondos expropiacion compra\n",
      "Tweet 2: tere_marinovic ademas nueva constitucion garantiza acceso casa propia explicaste venezolanos tambien\n",
      "------------------------------\n",
      "Cantidad de pares similares (s >= 0.3): 27055 (5.42%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "find_tweet_pairs(tweets_sample, 2, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33c604",
   "metadata": {},
   "source": [
    "#### k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee4fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando similitud: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 499500/499500 [00:24<00:00, 20269.40par/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentil 0:\n",
      "Tweet 1: angeldlacruz_ alerta confirma convencion actual gobierno boric izquierda quieren expropiar robar ahorros\n",
      "Tweet 2: juanpabloswett daniel stingo confirma berfontaine tenia razon heredable plata castellano robaran\n",
      "------------------------------\n",
      "Percentil 25:\n",
      "Tweet 1: mister_wolf_0 udi canal libertad desarrollo elisa loncon tremenda elisaloncon enfrentar programa lleno\n",
      "Tweet 2: elisaloncon razon rechazar gracias\n",
      "------------------------------\n",
      "Percentil 50:\n",
      "Tweet 1: arturozunigaj derecha propuso bajar quorum reformas constitucionales via presidente udi javiermaca\n",
      "Tweet 2: mister_wolf_0 rechazo caera mentiras partir ahora nuevo texto constituyente sera pilar derribar\n",
      "------------------------------\n",
      "Percentil 75:\n",
      "Tweet 1: retirototalafp tere_marinovic explica paso paso expropiaran ahorros quintoretirourgente retirototalafp qui\n",
      "Tweet 2: cgabriel01 tere_marinovic benbrereton18 esperanza\n",
      "------------------------------\n",
      "Percentil 95:\n",
      "Tweet 1: kakaroto12345 eivor877 tere_marinovic wea\n",
      "Tweet 2: joseantoniokast tere_marinovic humorista menos\n",
      "------------------------------\n",
      "Cantidad de pares similares (s >= 0.1): 33160 (6.64%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "find_tweet_pairs(tweets_sample, 3, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b5d32",
   "metadata": {},
   "source": [
    "#### k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce237eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando similitud: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 499500/499500 [00:26<00:00, 19049.25par/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentil 0:\n",
      "Tweet 1: angeldlacruz_ alerta confirma convencion actual gobierno boric izquierda quieren expropiar robar ahorros\n",
      "Tweet 2: criordor llego dia acabo trabajo convencionconstitucional sentimos alegria logrado gracias todas\n",
      "------------------------------\n",
      "Percentil 25:\n",
      "Tweet 1: angeldlacruz_ alerta confirma convencion actual gobierno boric izquierda quieren expropiar robar ahorros\n",
      "Tweet 2: bdelamaza leguleyada tramposa grupo convencionales presento viernes comision copia exacta norma rechazada\n",
      "------------------------------\n",
      "Percentil 50:\n",
      "Tweet 1: tere_marinovic sabe usted vota convencion constitucional respecto inmigracion ilegal aqui puede verlo\n",
      "Tweet 2: 2018_enrique tere_marinovic habra hacer campana rechazo mejor jefa campana\n",
      "------------------------------\n",
      "Percentil 75:\n",
      "Tweet 1: tere_marinovic presidente chile diciendole salga aca mujer espacio publico\n",
      "Tweet 2: black_hat_ok gran parte ventaja rechazo debemos grandes mujeres tere_marinovic rocicantuarias\n",
      "------------------------------\n",
      "Percentil 95:\n",
      "Tweet 1: criordor recomiendo entrevista poeta raul zurita gran esperanza veo sensibilidad nueva nuevaconstitucion\n",
      "Tweet 2: jaime_bassa unidad esperanza aprobemos chile sonamos lanuevaconstitucionesnuestra\n",
      "------------------------------\n",
      "Cantidad de pares similares (s >= 0.05): 42196 (8.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "find_tweet_pairs(tweets_sample, 4, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcd591",
   "metadata": {},
   "source": [
    "Los resultados que m√°s me hacen sentido son k=3 y s=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a7b16",
   "metadata": {},
   "source": [
    "# Locally Sensitive Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0521514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b7710a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4592806/4592806 [32:11<00:00, 2377.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_minhash(s):\n",
    "    # Obtiene los k-shingles del texto\n",
    "    shingle_set = get_k_shingles(s)\n",
    "\n",
    "    # Crea un objeto MinHash con 16 permutaciones\n",
    "    m = MinHash(num_perm=16)\n",
    "\n",
    "    for s in shingle_set:\n",
    "        m.update(s.encode('latin1'))\n",
    "\n",
    "    return m\n",
    "\n",
    "# Aplica la funci√≥n get_minhash a cada tweet para obtener los MinHash\n",
    "processed_tweets['minhash'] = processed_tweets['text'].progress_apply(get_minhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b43592a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye el √≠ndice LSH\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca267a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4592806/4592806 [01:10<00:00, 65197.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inserta cada MinHash en el √≠ndice LSH\n",
    "for i, mh in tqdm(processed_tweets['minhash'].items(), total=len(processed_tweets)):\n",
    "    lsh.insert(str(i), mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd1c06",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c70a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(processed_tweets, idx, s, k):\n",
    "    # Lista para almacenar los resultados\n",
    "    results = []\n",
    "    \n",
    "    # Obtiene el MinHash del tweet en el √≠ndice\n",
    "    mh_idx = processed_tweets.loc[idx, 'minhash']\n",
    "\n",
    "    # Encuentra los vecinos en el √≠ndice LSH\n",
    "    lsh_keys = lsh.query(mh_idx)\n",
    "    \n",
    "    # Se obtiene el text\n",
    "    text_idx = processed_tweets.loc[idx, 'text']\n",
    "    \n",
    "    # Para cada vecino\n",
    "    for key in lsh_keys:\n",
    "        # Obtiene el MinHash del vecino\n",
    "        mh_neighbor = processed_tweets.loc[int(key), 'minhash']\n",
    "        \n",
    "        # Se obtiene el text del vecino\n",
    "        text_neighbor = processed_tweets.loc[int(key), 'text']\n",
    "        \n",
    "        # Calcula la similitud de Jaccard\n",
    "        jaccard_sim = jaccard_similarity(get_k_shingles(text_idx, k), get_k_shingles(text_neighbor, k))\n",
    "        \n",
    "        # Si la similitud de Jaccard supera el umbral s, guarda el ID del vecino y la similitud\n",
    "        if jaccard_sim >= s:\n",
    "            results.append((processed_tweets.loc[int(key), 'id'], jaccard_sim))\n",
    "            \n",
    "    return (processed_tweets.loc[idx, 'id'], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "18e4994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentiles(tweets, tweet_id, neighbors):\n",
    "    # Obtiene los IDs y las similitudes de los vecinos\n",
    "    neighbor_ids, sims = zip(*neighbors)\n",
    "    \n",
    "    # Convierte las similitudes en un array de NumPy para c√°lculos m√°s f√°ciles\n",
    "    sims = np.array(sims)\n",
    "    \n",
    "    # Calcula los percentiles\n",
    "    p0 = np.percentile(sims, 0)\n",
    "    p25 = np.percentile(sims, 10)\n",
    "    p75 = np.percentile(sims, 20)\n",
    "    p95 = np.percentile(sims, 95)\n",
    "    \n",
    "    # Imprime el tweet original\n",
    "    print(\"Tweet original:\", tweets[tweets['id'] == tweet_id]['text'].values[0])\n",
    "    print(\"------------------------------\")\n",
    "    # Imprime los vecinos en cada percentil\n",
    "    for p, percentile in zip([p0, p25, p75, p95], [0, 10, 20, 95]):\n",
    "        # Encuentra el vecino m√°s cercano al percentil actual\n",
    "        closest_neighbor_id = neighbor_ids[np.argmin(np.abs(sims - p))]\n",
    "        \n",
    "        # Imprime el texto del vecino y la similitud\n",
    "        print(\"\\nVecino del percentil {} (similitud = {:.4f}):\".format(percentile, p))\n",
    "        print(tweets[tweets['id'] == closest_neighbor_id]['text'].values[0])\n",
    "        print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "afbd636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet original: RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs. comienza nuestro programa #DignificarelTrabajo en @uchileradio, con la Presidenta de @conve‚Ä¶\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 0 (similitud = 0.1008):\n",
      "Ma√±ana en el Parque Quinta Normal. Vaya y comparta con nuestra gente. Lo esperamos!!! https://t.co/EyOkKPSxKy\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 10 (similitud = 0.1371):\n",
      "@BenitoBaranda @uchileradio Cara de ra‚Ä¶. Con las lucas de otros .. trabaja wn\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 20 (similitud = 0.1517):\n",
      "RT @MEQChile: Ahora s√≠, ¬°ya estamos en Concepci√≥n!ü•∞ Comenzamos nuestras actividades en el B√≠o B√≠o con una entrevista en el programa \"Nuestr‚Ä¶\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 95 (similitud = 1.0000):\n",
      "RT @UTDTrabajoDigno: Ma√±ana jueves a las 18hrs. comienza nuestro programa #DignificarelTrabajo en @uchileradio, con la Presidenta de @conve‚Ä¶\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Obteniendo los vecinos\n",
    "idx_tweet, idx_neighbors = get_neighbors(processed_tweets, 1, 0.1, 3)\n",
    "\n",
    "# Imprimiendo los percentiles\n",
    "print_percentiles(tweets, idx_tweet, idx_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "40c9e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet original: RT @24HorasTVN: üìÉ #ElPa√≠sQueQueremos  \n",
      "\n",
      "@cretton15 :\"Creo que la Convenci√≥n Constitucional es uno de los organismos menos democr√°ticos que‚Ä¶\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 0 (similitud = 0.1000):\n",
      "@patriciapolitz @convencioncl @sebastian_gray @KarolCariola Hasta el convencional curao habla we√°s m√°s coherentes y reales que tus encuestas\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 10 (similitud = 0.1060):\n",
      "RT @PierreCurieD: Ser√≠a bueno que en la gira de la CC a Antofagasta, el Convencional @danielstingo les diga en su cara a los mineros que lo‚Ä¶\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 20 (similitud = 0.1257):\n",
      "RT @MEQChile: Hoy la #Convenci√≥nConstitucional sesion√≥ en las Ruinas de Huanchaca, Antofagasta. Precioso lugar, un patrimonio lleno de hist‚Ä¶\n",
      "------------------------------\n",
      "\n",
      "Vecino del percentil 95 (similitud = 1.0000):\n",
      "RT @24HorasTVN: üìÉ #ElPa√≠sQueQueremos  \n",
      "\n",
      "@cretton15 :\"Creo que la Convenci√≥n Constitucional es uno de los organismos menos democr√°ticos que‚Ä¶\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Obteniendo los vecinos\n",
    "idx_tweet, idx_neighbors = get_neighbors(processed_tweets, 2_000_000, 0.1, 3)\n",
    "\n",
    "# Imprimiendo los percentiles\n",
    "print_percentiles(tweets, idx_tweet, idx_neighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
